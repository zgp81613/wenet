<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>wenet.utils.mask module &mdash; wenet  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="wenet.utils.scheduler module" href="wenet.utils.scheduler.html" />
    <link rel="prev" title="wenet.utils.init_model module" href="wenet.utils.init_model.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            wenet
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../install.html">Install</a></li>
<li class="toctree-l1"><a class="reference internal" href="../train.html">How to train models?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../production.html">Production Runtime</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../reference.html">Reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../python_binding.html">Python Binding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../papers.html">Papers</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="modules.html">Python API Reference</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="wenet.html">wenet package</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="wenet.html#subpackages">Subpackages</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">wenet</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../reference.html">Reference</a></li>
          <li class="breadcrumb-item"><a href="modules.html">Python API Reference</a></li>
          <li class="breadcrumb-item"><a href="wenet.html">wenet package</a></li>
          <li class="breadcrumb-item"><a href="wenet.utils.html">wenet.utils package</a></li>
      <li class="breadcrumb-item active">wenet.utils.mask module</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/python_api/wenet.utils.mask.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-wenet.utils.mask">
<span id="wenet-utils-mask-module"></span><h1>wenet.utils.mask module<a class="headerlink" href="#module-wenet.utils.mask" title="Permalink to this heading"></a></h1>
<dl class="py function">
<dt class="sig sig-object py" id="wenet.utils.mask.add_optional_chunk_mask">
<span class="sig-prename descclassname"><span class="pre">wenet.utils.mask.</span></span><span class="sig-name descname"><span class="pre">add_optional_chunk_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">xs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">masks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_dynamic_chunk</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_dynamic_left_chunk</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">decoding_chunk_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">static_chunk_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_decoding_left_chunks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/wenet/utils/mask.html#add_optional_chunk_mask"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wenet.utils.mask.add_optional_chunk_mask" title="Permalink to this definition"></a></dt>
<dd><p>Apply optional mask for encoder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>torch.Tensor</em>) – padded input, (B, L, D), L for max length</p></li>
<li><p><strong>mask</strong> (<em>torch.Tensor</em>) – mask for xs, (B, 1, L)</p></li>
<li><p><strong>use_dynamic_chunk</strong> (<em>bool</em>) – whether to use dynamic chunk or not</p></li>
<li><p><strong>use_dynamic_left_chunk</strong> (<em>bool</em>) – whether to use dynamic left chunk for
training.</p></li>
<li><p><strong>decoding_chunk_size</strong> (<em>int</em>) – decoding chunk size for dynamic chunk, it’s
0: default for training, use random dynamic chunk.
&lt;0: for decoding, use full chunk.
&gt;0: for decoding, use fixed chunk size as set.</p></li>
<li><p><strong>static_chunk_size</strong> (<em>int</em>) – chunk size for static chunk training/decoding
if it’s greater than 0, if use_dynamic_chunk is true,
this parameter will be ignored</p></li>
<li><p><strong>num_decoding_left_chunks</strong> – number of left chunks, this is for decoding,
the chunk size is decoding_chunk_size.
&gt;=0: use num_decoding_left_chunks
&lt;0: use all left chunks</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>chunk mask of the input xs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="wenet.utils.mask.make_non_pad_mask">
<span class="sig-prename descclassname"><span class="pre">wenet.utils.mask.</span></span><span class="sig-name descname"><span class="pre">make_non_pad_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lengths</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/wenet/utils/mask.html#make_non_pad_mask"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wenet.utils.mask.make_non_pad_mask" title="Permalink to this definition"></a></dt>
<dd><p>Make mask tensor containing indices of non-padded part.</p>
<p>The sequences in a batch may have different lengths. To enable
batch computing, padding is need to make all sequence in same
size. To avoid the padding part pass value to context dependent
block such as attention or convolution , this padding part is
masked.</p>
<p>This pad_mask is used in both encoder and decoder.</p>
<p>1 for non-padded part and 0 for padded part.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>lengths</strong> (<em>torch.Tensor</em>) – Batch of lengths (B,).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>mask tensor containing indices of padded part.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lengths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">make_non_pad_mask</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span>
<span class="go">masks = [[1, 1, 1, 1 ,1],</span>
<span class="go">         [1, 1, 1, 0, 0],</span>
<span class="go">         [1, 1, 0, 0, 0]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="wenet.utils.mask.make_pad_mask">
<span class="sig-prename descclassname"><span class="pre">wenet.utils.mask.</span></span><span class="sig-name descname"><span class="pre">make_pad_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lengths</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_len</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/wenet/utils/mask.html#make_pad_mask"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wenet.utils.mask.make_pad_mask" title="Permalink to this definition"></a></dt>
<dd><p>Make mask tensor containing indices of padded part.</p>
<p>See description of make_non_pad_mask.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>lengths</strong> (<em>torch.Tensor</em>) – Batch of lengths (B,).</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Mask tensor containing indices of padded part.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lengths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">make_pad_mask</span><span class="p">(</span><span class="n">lengths</span><span class="p">)</span>
<span class="go">masks = [[0, 0, 0, 0 ,0],</span>
<span class="go">         [0, 0, 0, 1, 1],</span>
<span class="go">         [0, 0, 1, 1, 1]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="wenet.utils.mask.mask_finished_preds">
<span class="sig-prename descclassname"><span class="pre">wenet.utils.mask.</span></span><span class="sig-name descname"><span class="pre">mask_finished_preds</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pred</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flag</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eos</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/wenet/utils/mask.html#mask_finished_preds"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wenet.utils.mask.mask_finished_preds" title="Permalink to this definition"></a></dt>
<dd><p>If a sequence is finished, all of its branch should be &lt;eos&gt;</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pred</strong> (<em>torch.Tensor</em>) – A int array with shape
(batch_size * beam_size, beam_size).</p></li>
<li><p><strong>flag</strong> (<em>torch.Tensor</em>) – A bool array with shape
(batch_size * beam_size, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(batch_size * beam_size).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="wenet.utils.mask.mask_finished_scores">
<span class="sig-prename descclassname"><span class="pre">wenet.utils.mask.</span></span><span class="sig-name descname"><span class="pre">mask_finished_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">score</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flag</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/wenet/utils/mask.html#mask_finished_scores"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wenet.utils.mask.mask_finished_scores" title="Permalink to this definition"></a></dt>
<dd><p>If a sequence is finished, we only allow one alive branch. This function
aims to give one branch a zero score and the rest -inf score.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>score</strong> (<em>torch.Tensor</em>) – A real value array with shape
(batch_size * beam_size, beam_size).</p></li>
<li><p><strong>flag</strong> (<em>torch.Tensor</em>) – A bool array with shape
(batch_size * beam_size, 1).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(batch_size * beam_size, beam_size).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="wenet.utils.mask.subsequent_chunk_mask">
<span class="sig-prename descclassname"><span class="pre">wenet.utils.mask.</span></span><span class="sig-name descname"><span class="pre">subsequent_chunk_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">chunk_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_left_chunks</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">device</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">device(type='cpu')</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/wenet/utils/mask.html#subsequent_chunk_mask"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wenet.utils.mask.subsequent_chunk_mask" title="Permalink to this definition"></a></dt>
<dd><dl class="simple">
<dt>Create mask for subsequent steps (size, size) with chunk size,</dt><dd><p>this is for streaming encoder</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<em>int</em>) – size of mask</p></li>
<li><p><strong>chunk_size</strong> (<em>int</em>) – size of chunk</p></li>
<li><p><strong>num_left_chunks</strong> (<em>int</em>) – number of left chunks
&lt;0: use full chunk
&gt;=0: use num_left_chunks</p></li>
<li><p><strong>device</strong> (<em>torch.device</em>) – “cpu” or “cuda” or torch.Tensor.device</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>mask</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">subsequent_chunk_mask</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="go">[[1, 1, 0, 0],</span>
<span class="go"> [1, 1, 0, 0],</span>
<span class="go"> [1, 1, 1, 1],</span>
<span class="go"> [1, 1, 1, 1]]</span>
</pre></div>
</div>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="wenet.utils.mask.subsequent_mask">
<span class="sig-prename descclassname"><span class="pre">wenet.utils.mask.</span></span><span class="sig-name descname"><span class="pre">subsequent_mask</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">device</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">device(type='cpu')</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="reference internal" href="../_modules/wenet/utils/mask.html#subsequent_mask"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#wenet.utils.mask.subsequent_mask" title="Permalink to this definition"></a></dt>
<dd><p>Create mask for subsequent steps (size, size).</p>
<p>This mask is used only in decoder which works in an auto-regressive mode.
This means the current step could only do attention with its left steps.</p>
<p>In encoder, fully attention is used when streaming is not necessary and
the sequence is not long. In this  case, no attention mask is needed.</p>
<p>When streaming is need, chunk-based attention is used in encoder. See
subsequent_chunk_mask for the chunk-based attention mask.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<em>int</em>) – size of mask</p></li>
<li><p><strong>device</strong> (<em>str</em>) – “cpu” or “cuda” or torch.Tensor.device</p></li>
<li><p><strong>dtype</strong> (<em>torch.device</em>) – result dtype</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>mask</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>torch.Tensor</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">subsequent_mask</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="go">[[1, 0, 0],</span>
<span class="go"> [1, 1, 0],</span>
<span class="go"> [1, 1, 1]]</span>
</pre></div>
</div>
</dd></dl>

</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="wenet.utils.init_model.html" class="btn btn-neutral float-left" title="wenet.utils.init_model module" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="wenet.utils.scheduler.html" class="btn btn-neutral float-right" title="wenet.utils.scheduler module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, wenet-team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>